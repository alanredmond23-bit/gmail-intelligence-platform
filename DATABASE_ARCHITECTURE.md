# Database Architecture: Supabase PostgreSQL

## Overview

Gmail Intelligence Platform uses **Supabase PostgreSQL** for scalable, production-ready data storage with real-time capabilities.

**Your Project**: `fifybuzwfaegloijrmqb` (https://app.supabase.com)

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gmail Intelligence                       â”‚
â”‚                      Application                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ supabase_ â”‚           â”‚  database.py â”‚
    â”‚ client.py â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   (Interface)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Supabase Client (REST API)                    â”‚
    â”‚  https://api.supabase.com/                     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL 14+ Database                       â”‚
    â”‚  (fifybuzwfaegloijrmqb.supabase.co)           â”‚
    â”‚                                                â”‚
    â”‚  â”œâ”€ emails (email records)                     â”‚
    â”‚  â”œâ”€ attachments (file metadata)                â”‚
    â”‚  â”œâ”€ entities (NER results)                     â”‚
    â”‚  â”œâ”€ search_history (tracking)                  â”‚
    â”‚  â”œâ”€ Full-Text Search Indexes (GIN)             â”‚
    â”‚  â”œâ”€ PostgreSQL Functions (FTS)                 â”‚
    â”‚  â””â”€ Triggers (auto timestamps)                 â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  S3 Storage (Attachments)                      â”‚
    â”‚  ~/Supabase-S3/                                â”‚
    â”‚  (19 MB/s write, 3ms directory listing)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Model

### Emails Table
```
emails
â”œâ”€â”€ id (BIGSERIAL PRIMARY KEY)
â”œâ”€â”€ message_id (TEXT UNIQUE) ............ Gmail message ID
â”œâ”€â”€ gmail_id (TEXT) ..................... Gmail thread ID
â”œâ”€â”€ from_address (TEXT) ................. Sender email
â”œâ”€â”€ to_addresses (TEXT) ................. Recipient list (JSON)
â”œâ”€â”€ subject (TEXT) ...................... Email subject
â”œâ”€â”€ body (TEXT) ......................... Email body (full text)
â”œâ”€â”€ html_body (TEXT) .................... HTML version
â”œâ”€â”€ timestamp (TIMESTAMP TZ) ............ Sent date
â”œâ”€â”€ thread_id (TEXT) .................... Gmail thread ID
â”œâ”€â”€ labels (TEXT) ....................... Gmail labels (JSON)
â”œâ”€â”€ sentiment (VARCHAR) ................. Analysis result
â”œâ”€â”€ sentiment_confidence (NUMERIC) ...... Confidence 0-1
â”œâ”€â”€ is_privileged (BOOLEAN) ............. Privilege flag
â”œâ”€â”€ privilege_confidence (NUMERIC) ...... Confidence 0-1
â”œâ”€â”€ created_at (TIMESTAMP TZ) ........... Stored timestamp
â””â”€â”€ updated_at (TIMESTAMP TZ) ........... Last modified

Indexes:
â”œâ”€â”€ PRIMARY KEY (id)
â”œâ”€â”€ UNIQUE (message_id)
â”œâ”€â”€ INDEX (from_address)
â”œâ”€â”€ INDEX (timestamp DESC)
â”œâ”€â”€ INDEX (sentiment)
â”œâ”€â”€ INDEX (is_privileged)
â”œâ”€â”€ FTS INDEX (body) .................... Full-text search
â””â”€â”€ FTS INDEX (subject)
```

### Attachments Table
```
attachments
â”œâ”€â”€ id (BIGSERIAL PRIMARY KEY)
â”œâ”€â”€ email_id (BIGINT FK) ................ Reference to emails
â”œâ”€â”€ filename (TEXT) ..................... Original filename
â”œâ”€â”€ file_path (TEXT) .................... S3 path
â”œâ”€â”€ mime_type (TEXT) .................... Content type
â”œâ”€â”€ size_bytes (BIGINT) ................. File size
â””â”€â”€ created_at (TIMESTAMP TZ) ........... Created timestamp

Indexes:
â”œâ”€â”€ PRIMARY KEY (id)
â””â”€â”€ INDEX (email_id)
```

### Entities Table
```
entities
â”œâ”€â”€ id (BIGSERIAL PRIMARY KEY)
â”œâ”€â”€ email_id (BIGINT FK) ................ Reference to emails
â”œâ”€â”€ entity_type (TEXT) .................. PERSON, ORG, LOCATION
â”œâ”€â”€ entity_value (TEXT) ................. Extracted text
â”œâ”€â”€ confidence (NUMERIC) ................ 0-1 confidence
â””â”€â”€ created_at (TIMESTAMP TZ) ........... Created timestamp

Indexes:
â”œâ”€â”€ PRIMARY KEY (id)
â”œâ”€â”€ INDEX (email_id)
â””â”€â”€ INDEX (entity_type)
```

### Search History Table
```
search_history
â”œâ”€â”€ id (BIGSERIAL PRIMARY KEY)
â”œâ”€â”€ purpose (TEXT) ...................... Why search was done
â”œâ”€â”€ query (TEXT) ........................ Query executed
â”œâ”€â”€ results_count (INTEGER) ............. Results found
â””â”€â”€ created_at (TIMESTAMP TZ) ........... Timestamp

Use Case: Track searches for analytics
```

---

## Relationships

```
emails (1) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (M) attachments
  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (M) entities
```

- **emails.id** â† attachments.email_id
- **emails.id** â† entities.email_id
- Cascade delete: Removing email removes related attachments and entities

---

## Key Features

### 1. Full-Text Search
```sql
-- PostgreSQL FTS on body and subject
search_emails(query TEXT, max_results INT)
```

**Usage**:
```python
results = db.search_emails("bankruptcy lawsuit", limit=20)
```

### 2. Indexes for Performance

| Index | Purpose | Query Type |
|-------|---------|-----------|
| from_address | Filter by sender | WHERE from_address = '...' |
| timestamp DESC | Date range queries | WHERE timestamp > ... |
| sentiment | Sentiment filtering | WHERE sentiment = 'positive' |
| is_privileged | Privilege detection | WHERE is_privileged = true |
| FTS (body, subject) | Full-text search | to_tsvector() @@ plainto_tsquery() |

### 3. Automatic Timestamps
- `created_at`: Set on insert (CURRENT_TIMESTAMP)
- `updated_at`: Auto-updated on any modification (TRIGGER)

### 4. Data Integrity
- Primary keys on all tables
- Foreign key constraints (attachments, entities)
- Unique constraint on message_id (prevents duplicates)

---

## Performance Characteristics

### Inserts
```python
# Single insert: ~50ms
db.insert_email(email_dict)

# Batch insert: ~2-5ms per email
db.batch_insert_emails(1000_emails)  # ~2-5 seconds total
```

### Queries
```python
# Filter by indexed column: ~10-50ms
db.query_emails(where="from_address=eq.test@example.com", limit=100)

# Full-text search: ~50-200ms
db.search_emails("bankruptcy", limit=50)

# Pagination: Constant time regardless of offset
db.query_emails(limit=10, offset=1000)
```

### Concurrent Operations
- Supabase handles up to 100+ concurrent connections
- Connection pooling enabled by default
- Row-level locking for updates

---

## S3 Integration

Attachments stored on **Supabase S3** mount:

```
~/Supabase-S3/
â”œâ”€â”€ attachments/
â”‚   â”œâ”€â”€ email_123/
â”‚   â”‚   â”œâ”€â”€ document.pdf
â”‚   â”‚   â”œâ”€â”€ image.png
â”‚   â”‚   â””â”€â”€ archive.zip
â”‚   â””â”€â”€ email_456/
â”‚       â””â”€â”€ contract.docx
â””â”€â”€ backups/
    â”œâ”€â”€ 20260207.sql
    â””â”€â”€ 20260206.sql
```

**Performance**: 19 MB/s write, 3ms directory listing

**Fleet Sync**: All machines (WORKHORSE, ADMIN, QUICKS) access same S3 mount

---

## Multi-Tenant Support

### Optional: Row-Level Security (RLS)

Enable per-user data isolation:

```sql
ALTER TABLE emails ENABLE ROW LEVEL SECURITY;

CREATE POLICY "users_see_own_emails" ON emails
  FOR ALL USING (auth.uid()::text = user_id);
```

Currently disabled for single-user usage. Enable when needed.

---

## Real-Time Subscriptions

### Enable Real-Time Monitoring

```python
from supabase import create_client

client = create_client(supabase_url, supabase_key)

# Subscribe to email changes
channel = client.realtime.subscribe("emails")
channel.on("INSERT", lambda x: print(f"New email: {x['data']['message_id']}"))
channel.on("UPDATE", lambda x: print(f"Updated: {x['data']['id']}"))
channel.subscribe()
```

### Use Cases
- Live dashboard updates
- Incremental sync notifications
- Real-time privilege alerts
- Analysis completion notifications

---

## Backup & Recovery

### Automated Backups
- Supabase backs up daily
- Point-in-time recovery available
- Backup retention: 7 days (default)

### Manual Backup

```bash
# Backup to file
pg_dump --data-only $SUPABASE_URL -U postgres > backup.sql

# Backup to S3
pg_dump --data-only $SUPABASE_URL -U postgres | \
  gzip > ~/Supabase-S3/backups/$(date +%Y%m%d).sql.gz
```

---

## Security

### Network Security
- All connections HTTPS/TLS
- Supabase handles SSL termination
- No exposed database port

### Authentication
- **Anon Key**: Public API key, use for frontend
- **Service Key**: Private, for backend/admin operations
- Both keys in environment variables (not committed to git)

### Row-Level Security (RLS)
- Optional per-user data isolation
- Policies enforce access control at database level
- Automatically applied to all queries

### Rate Limiting
- Supabase enforces rate limits
- Implement backoff on rate limit errors
- See error_recovery.py for retry logic

---

## Monitoring & Debugging

### In Supabase Dashboard

1. **Database > Query Performance**
   - View slowest queries
   - Identify missing indexes

2. **Database > Connections**
   - Monitor active connections
   - Kill stuck queries

3. **Logs > Database**
   - View all database operations
   - Search for errors

### In Python

```python
# Check connection
from gmail_intelligence.storage.database import DatabaseManager

db = DatabaseManager()
stats = db.get_stats()
print(f"Connected: {stats['status']}")
print(f"Total emails: {stats['total_emails']}")
```

---

## Optimization Tips

### Query Optimization
1. **Use pagination** for large result sets
2. **Index on WHERE clauses** (already created)
3. **Limit projections** to needed columns
4. **Batch operations** for bulk work

### Application Optimization
1. **Connection pooling** (automatic)
2. **Cache frequently accessed data** (Redis - future)
3. **Async queries** for non-blocking operations
4. **Incremental sync** instead of full refresh

---

## Cost Considerations

### Supabase Pricing Tiers

**Free Tier**:
- 500 MB database
- 1 GB file storage
- 2-core CPU
- Good for development/testing

**Pro Tier** ($25/month):
- 8 GB database
- 100 GB file storage
- 2-core CPU (scalable)
- Suitable for production

**Enterprise**:
- Custom database size
- Custom file storage
- Dedicated resources
- SLA guarantees

### Optimization for Cost
- Use S3 for attachments (separate storage)
- Archive old emails to cold storage
- Implement data retention policies
- Monitor storage growth

---

## Migration Path

If switching from another database:

1. **Prepare schema** (done: schema.sql)
2. **Migrate data** with bulk insert
3. **Validate data** integrity
4. **Test queries** and performance
5. **Cut over** to new database

See migration examples in Phase 2 implementation.

---

## Next Steps

1. âœ… Get Supabase credentials
2. âœ… Run schema.sql in SQL Editor
3. âœ… Set SUPABASE_URL and SUPABASE_KEY
4. âœ… Test connection: `db.initialize()`
5. âœ… Begin Phase 2: IMAP & Gmail API implementation

---

**Database Architecture Complete! Ready for Phase 2.** ðŸš€
